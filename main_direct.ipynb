{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7525b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Local modules\n",
    "from module.data_loader import OsirisData\n",
    "from module.dataset import *\n",
    "from module.modeling import randomforestregressormodel_train, lassoregressionmodel_train, supportvectormachinemodel_train\n",
    "from module.modeling import randomforestregressormodel_pred, lassoregressionmodel_pred, supportvectormachinemodel_pred\n",
    "from module.features import *\n",
    "from module.settings import load_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630b8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which settings to load\n",
    "settings_type = 'custom'  # [default,custom] Change to 'custom' to load custom settings\n",
    "dataloader = \"db\" # Change to 'file' for file input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ddb914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrain_models': True, 'separator': ',', 'dropout_column': 'dropout', 'studentnumber_column': 'STUDENTNUMMER', 'save_method': 'xlsx', 'PROJ_ROOT': '.', 'DATA_DIR': './data', 'RAW_DATA_DIR': './data/raw', 'INTERIM_DATA_DIR': './data/interim', 'PROCESSED_DATA_DIR': './data/processed', 'EXTERNAL_DATA_DIR': './data/external', 'MODELS_DIR': './models', 'synth_data_dir_train': './data/raw/synth_data_train.csv', 'synth_data_dir_pred': './data/raw/synth_data_pred.csv', 'user_data_dir_train': './data/raw/user_data/train.csv', 'user_data_dir_pred': './data/raw/user_data/pred.csv', 'random_seed': 42, 'rf_parameters': {'bootstrap': [True, False], 'max_depth': [2, 3, 4], 'max_features': [3, 4, 5], 'min_samples_leaf': [3, 4, 5], 'min_samples_split': [2, 3, 5], 'n_estimators': [100, 200, 300]}, 'lasso_parameters': {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]}, 'svm_parameters': {'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1], 'kernel': ['rbf']}}\n"
     ]
    }
   ],
   "source": [
    "config_file = 'config.yaml'\n",
    "settings = load_settings(config_file, settings_type)\n",
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d23cac45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__ Init done __\n",
      "inschrijvingen geladen...\n",
      "verzuimdata geladen...\n",
      "vooropleidingdata geladen...\n"
     ]
    }
   ],
   "source": [
    "# Check if train.csv and pred.csv exist in user_data folder, otherwise load synthetic datasests\n",
    "# When user data is loaded and an error occurs here, please check if the sep = '\\t' needs to be changed in the config.yaml file to another separator like ',' or '.'\n",
    "# This should be the same as the separator used in your .csv file\n",
    "\n",
    "if dataloader == 'file':\n",
    "    if os.path.exists(settings.user_data_dir_train) and os.path.exists(settings.user_data_dir_pred):\n",
    "        train_path,pred_path = user_data_dir_train, user_data_dir_pred\n",
    "        print ('User datasets found')\n",
    "    else:\n",
    "        train_path,pred_path = settings.synth_data_dir_train, settings.synth_data_dir_pred\n",
    "        print ('Pre-uploaded synthetic datasets found')\n",
    "        \n",
    "    # train_df = pd.read_csv(train_path, sep = separator, engine='python')\n",
    "    pred_df = pd.read_csv(pred_path, sep = separator, engine='python')\n",
    "elif dataloader == 'db':\n",
    "    team=\"BB\"\n",
    "    pred_cohort = 2024\n",
    "    train_cohort_min = 2023\n",
    "    db = OsirisData(env_path=\"./\")\n",
    "    # train_df = db.get_dataset(team=\"BB\",min_cohort=train_cohort_min,max_cohort=pred_cohort-1)\n",
    "    pred_df = db.get_dataset(team=team,min_cohort=pred_cohort,max_cohort=pred_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b43c1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inschrijvingen geladen...\n",
      "verzuimdata geladen...\n",
      "vooropleidingdata geladen...\n"
     ]
    }
   ],
   "source": [
    "if settings.retrain_models == True:\n",
    "    if dataloader == 'file':\n",
    "        train_df = pd.read_csv(train_path, sep = separator, engine='python')\n",
    "    elif dataloader == 'db':\n",
    "        # pred_cohort = 2024\n",
    "        # train_cohort_min = 2023\n",
    "        # db = OsirisData(env_path=\"./\")\n",
    "        train_df = db.get_dataset(team=team,min_cohort=train_cohort_min,max_cohort=pred_cohort-1)\n",
    "        # pred_df = db.get_dataset(team=\"BB\",min_cohort=pred_cohort,max_cohort=pred_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ffb433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data cleaning: drop rows that are duplicate and change any NA values to the average value of the column it's in. \n",
    "if settings.retrain_models == True:\n",
    "    train_basic_cl = basic_cleaning (train_df)\n",
    "pred_basic_cl = basic_cleaning (pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a0a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if there are columns in which all rows have the same value and delete these columns from the train and predict datasets \n",
    "if settings.retrain_models == True:\n",
    "    train_cleaned, pred_cleaned = remove_single_value_columns(train_basic_cl, pred_basic_cl)\n",
    "else: \n",
    "    train_cleaned, pred_cleaned = remove_single_value_columns(pred_basic_cl, pred_basic_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61f5206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned[settings.studentnumber_column]=train_cleaned[settings.studentnumber_column].astype(\"int\")\n",
    "pred_cleaned[settings.studentnumber_column]=pred_cleaned[settings.studentnumber_column].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c8e9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function that changes categorical data into numerical data so it can be used as input for the models \n",
    "train_processed, pred_processed = convert_categorical_to_dummies(train_cleaned, pred_cleaned, settings.dropout_column, settings.separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d9d74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function standardize_min_max to standardize the train and pred datasets using a min max scaler and save them as .csv files in the folder data/interim \n",
    "# These datasets can be used for the lasso and svm models, because reggression is sensitive to scaling \n",
    "train_df_sdd, pred_df_sdd = standardize_dataset(train_processed, pred_processed, settings.dropout_column, settings.separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea90352c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models on the data...\n",
      "Training random_forest_regressor with features:\n",
      "Index(['STUD_GENDER_M', 'STUD_GENDER_V', 'LEEFTIJD', 'VOOROPLNIVEAU_NAN',\n",
      "       'VOOROPLNIVEAU_VMBO_BB', 'VOOROPLNIVEAU_VMBO_GL',\n",
      "       'VOOROPLNIVEAU_VMBO_KB', 'VOOROPLNIVEAU_VMBO_TL', 'VOOROPLNIVEAU_MBO',\n",
      "       'TOTAALAANW3', 'TOTAALAANW6', 'TOTAALAANW10', 'AANW_PCT3', 'AANW_PCT6',\n",
      "       'AANW_PCT10', 'dropout'],\n",
      "      dtype='object')\n",
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n",
      "Training lasso_regression with features:\n",
      "Index(['STUD_GENDER_M', 'STUD_GENDER_V', 'LEEFTIJD', 'VOOROPLNIVEAU_NAN',\n",
      "       'VOOROPLNIVEAU_VMBO_BB', 'VOOROPLNIVEAU_VMBO_GL',\n",
      "       'VOOROPLNIVEAU_VMBO_KB', 'VOOROPLNIVEAU_VMBO_TL', 'VOOROPLNIVEAU_MBO',\n",
      "       'TOTAALAANW3', 'TOTAALAANW6', 'TOTAALAANW10', 'AANW_PCT3', 'AANW_PCT6',\n",
      "       'AANW_PCT10', 'dropout'],\n",
      "      dtype='object')\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "Training support_vector_machine with features:\n",
      "Index(['STUD_GENDER_M', 'STUD_GENDER_V', 'LEEFTIJD', 'VOOROPLNIVEAU_NAN',\n",
      "       'VOOROPLNIVEAU_VMBO_BB', 'VOOROPLNIVEAU_VMBO_GL',\n",
      "       'VOOROPLNIVEAU_VMBO_KB', 'VOOROPLNIVEAU_VMBO_TL', 'VOOROPLNIVEAU_MBO',\n",
      "       'TOTAALAANW3', 'TOTAALAANW6', 'TOTAALAANW10', 'AANW_PCT3', 'AANW_PCT6',\n",
      "       'AANW_PCT10', 'dropout'],\n",
      "      dtype='object')\n",
      "{'probability': True}\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    }
   ],
   "source": [
    "# Code checks if retrain_models = True or False in config.yaml file. \n",
    "# When using your own datasets, change retrain_models in the config.yaml file to True, so the models are trained on your own data. \n",
    "# Warning: training the models can take a long time depending on the size and contents of your data. \n",
    "if settings.retrain_models == True:\n",
    "    print ('Training models on the data...')\n",
    "    best_rf_model = randomforestregressormodel_train(\n",
    "        train_processed, settings.random_seed\n",
    "        , settings.dropout_column, settings.rf_parameters)\n",
    "    best_lasso_model = lassoregressionmodel_train(\n",
    "        train_df_sdd, settings.random_seed\n",
    "        , settings.dropout_column, settings.lasso_parameters)\n",
    "    best_svm_model = supportvectormachinemodel_train(\n",
    "        train_df_sdd, settings.random_seed\n",
    "        , settings.dropout_column, settings.svm_parameters)\n",
    "else:\n",
    "    print('retrain_models is False in the config.yaml file, loading the pre-trained models')\n",
    "# Folds = number of train/test splits of the dataset, candidates = models with different parameters and fits = folds * candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abad1f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STUD_GENDER_M', 'STUD_GENDER_V', 'LEEFTIJD', 'VOOROPLNIVEAU_NAN',\n",
       "       'VOOROPLNIVEAU_VMBO_BB', 'VOOROPLNIVEAU_VMBO_GL',\n",
       "       'VOOROPLNIVEAU_VMBO_KB', 'VOOROPLNIVEAU_VMBO_TL', 'VOOROPLNIVEAU_MBO',\n",
       "       'TOTAALAANW3', 'TOTAALAANW6', 'TOTAALAANW10', 'AANW_PCT3', 'AANW_PCT6',\n",
       "       'AANW_PCT10', 'dropout'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c79637b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STUDENTNUMMER', 'STUD_GENDER_M', 'STUD_GENDER_V', 'LEEFTIJD',\n",
       "       'VOOROPLNIVEAU_NAN', 'VOOROPLNIVEAU_VMBO_BB', 'VOOROPLNIVEAU_VMBO_GL',\n",
       "       'VOOROPLNIVEAU_VMBO_KB', 'VOOROPLNIVEAU_VMBO_TL', 'VOOROPLNIVEAU_MBO',\n",
       "       'TOTAALAANW3', 'TOTAALAANW6', 'TOTAALAANW10', 'AANW_PCT3', 'AANW_PCT6',\n",
       "       'AANW_PCT10', 'dropout'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7087355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the loaded models to predict on the datasets. \n",
    "# The lasso and SVM models use the standardized dataset ot predict an, but take the student numnbers from the \n",
    "# regular predict dataset. \n",
    "ranked_students_rf = randomforestregressormodel_pred (pred_processed, settings.dropout_column, settings.studentnumber_column)\n",
    "ranked_students_lasso = lassoregressionmodel_pred(pred_df_sdd, pred_processed, settings.dropout_column, settings.studentnumber_column)\n",
    "ranked_students_svm = supportvectormachinemodel_pred(pred_df_sdd, pred_processed, settings.dropout_column, settings.studentnumber_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d85b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file saved as .xlsx in the Z:\\FRITS\\DGO-WG3 folder\n"
     ]
    }
   ],
   "source": [
    "# Save the output files as either .xlsx or as three .csv files\n",
    "from pathlib import Path\n",
    "BASE_PATH = Path(\"Z:\\\\FRITS\\\\DGO-WG3\")\n",
    "if settings.save_method == 'xlsx':\n",
    "    writer = pd.ExcelWriter(BASE_PATH / f'{team}_ranked_students.xlsx', engine='xlsxwriter')\n",
    "    ranked_students_rf.to_excel(writer, sheet_name='Random Forest', startrow=0, startcol=0, index=False)\n",
    "    ranked_students_lasso.to_excel(writer, sheet_name='Lasso', startrow=0, startcol=0, index=False)\n",
    "    ranked_students_svm.to_excel(writer, sheet_name='Support Vector Machine', startrow=0, startcol=0, index=False)\n",
    "    writer.close()\n",
    "    print (f'Output file saved as .xlsx in the {BASE_PATH} folder')\n",
    "elif settings.save_method == 'csv':\n",
    "    ranked_students_rf.to_csv(BASE_PATH / f'{team}_ranked_students_rf.csv', sep='\\t', index=False)\n",
    "    ranked_students_lasso.to_csv(BASE_PATH / f'{team}_ranked_students_lasso.csv', sep='\\t', index=False)\n",
    "    ranked_students_svm.to_csv(BASE_PATH / f'{team}_ranked_students_svm.csv', sep='\\t', index=False)\n",
    "    print (f'Output files saved as .csv in the {BASE_PATH} folder')\n",
    "else:\n",
    "    print('Invalid save method. For save_method in the config.yaml file, please fill in \"xlsx\" or \"csv\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f8dbb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (2.3.1)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (2.3.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fritssteege\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0758e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.plot import (\n",
    "    generate_precision_plot, \n",
    "    generate_sensitivity_plot, \n",
    "    generate_svm_importance_plot,\n",
    "    generate_stoplight_evaluation,\n",
    "    save_model_metrics,\n",
    "    save_threshold_analysis,\n",
    "    extract_model_data,\n",
    "    sort_and_filter_data,\n",
    "    process_evaluation_results,\n",
    "    display_model_results,\n",
    "    get_coefficient_table,\n",
    "    get_top_svm_features,\n",
    "    analyze_missing_data,\n",
    "    parse_model_metrics,\n",
    "    display_top_features\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot styling\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.formatter.useoffset'] = False\n",
    "plt.rcParams['axes.formatter.limits'] = (-2, 2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "625a5d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Prediction failed for Random Forest: at least one array or dtype is required\n",
      "Warning: Prediction failed for Lasso: at least one array or dtype is required\n",
      "Warning: Prediction failed for SVM: at least one array or dtype is required\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\14\\ipykernel_16396\\2649993662.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      9\u001b[39m         \u001b[33m'Lasso'\u001b[39m: (test_data_sdd, best_lasso_model, \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m     10\u001b[39m         \u001b[33m'SVM'\u001b[39m: (test_data_sdd, best_svm_model, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     11\u001b[39m     }\n\u001b[32m     12\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m evaluation_results = generate_stoplight_evaluation(\n\u001b[32m     14\u001b[39m         model_predictions,\n\u001b[32m     15\u001b[39m         invite_pct=\u001b[32m20\u001b[39m\n\u001b[32m     16\u001b[39m     )\n",
      "\u001b[32mc:\\Users\\fritssteege\\Documents\\Python\\DGO-WG3\\Uitnodigingsregel\\module\\plot.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(model_predictions, invite_pct)\u001b[39m\n\u001b[32m    614\u001b[39m \n\u001b[32m    615\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m model_name, (y_true, y_pred) \u001b[38;5;28;01min\u001b[39;00m predictions.items():\n\u001b[32m    616\u001b[39m         model_metrics = []\n\u001b[32m    617\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;28;01min\u001b[39;00m thresholds:\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m             precision, recall = calculate_metrics_at_threshold(y_true, y_pred, threshold)\n\u001b[32m    619\u001b[39m             model_metrics.append((threshold, precision, recall))\n\u001b[32m    620\u001b[39m \n\u001b[32m    621\u001b[39m             \u001b[38;5;66;03m# If this is the main threshold (20%), get stoplight evaluation\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\fritssteege\\Documents\\Python\\DGO-WG3\\Uitnodigingsregel\\module\\plot.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(y_true, y_pred, threshold_pct)\u001b[39m\n\u001b[32m    569\u001b[39m \n\u001b[32m    570\u001b[39m         \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[32m    571\u001b[39m         selected_true = y_true.iloc[top_k_indices]\n\u001b[32m    572\u001b[39m         precision = selected_true.mean()\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m         recall = selected_true.sum() / y_true.sum() \u001b[38;5;28;01mif\u001b[39;00m y_true.sum() > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    574\u001b[39m \n\u001b[32m    575\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m precision, recall\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1575\u001b[39m     @final\n\u001b[32m   1576\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __nonzero__(self) -> NoReturn:\n\u001b[32m-> \u001b[39m\u001b[32m1577\u001b[39m         raise ValueError(\n\u001b[32m   1578\u001b[39m             f\"The truth value of a {type(self).__name__} is ambiguous. \"\n\u001b[32m   1579\u001b[39m             \u001b[33m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[39m\n\u001b[32m   1580\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_processed.drop(columns=[settings.dropout_column]),train_processed[settings.dropout_column],pred_processed.drop(columns=[settings.dropout_column]),pred_processed[settings.dropout_column]\n",
    "X_train_sdd, X_test_sdd, y_train_sdd, y_test_sdd = train_df_sdd.drop(columns=[settings.dropout_column]),train_df_sdd[settings.dropout_column],pred_df_sdd.drop(columns=[settings.dropout_column]),pred_df_sdd[settings.dropout_column]\n",
    "# drop_cols = [settings.studentnumber_column]\n",
    "# dr_cols = \n",
    "test_data_rf = pd.concat([X_test, y_test], axis=1)\n",
    "test_data_sdd = pd.concat([X_test_sdd, y_test_sdd], axis=1)\n",
    "model_predictions = {\n",
    "        'Random Forest': (test_data_rf, best_rf_model, False),\n",
    "        'Lasso': (test_data_sdd, best_lasso_model, True),\n",
    "        'SVM': (test_data_sdd, best_svm_model, True)\n",
    "    }\n",
    "    \n",
    "evaluation_results = generate_stoplight_evaluation(\n",
    "        model_predictions,\n",
    "        invite_pct=20\n",
    "    )\n",
    "save_model_metrics(\n",
    "            train_data=pd.concat([X_train, y_train], axis=1),\n",
    "            train_data_scaled=pd.concat([X_train_sdd, y_train_sdd], axis=1),\n",
    "            validation_data=test_data_rf,\n",
    "            validation_data_scaled=test_data_sdd,\n",
    "            rf_model=best_rf_model,\n",
    "            lasso_model=best_lasso_model,\n",
    "            svm_model=best_svm_model\n",
    "        )\n",
    "save_threshold_analysis(\n",
    "            train_data=pd.concat([X_train, y_train], axis=1),\n",
    "            train_data_scaled=pd.concat([X_train_sdd, y_train_sdd], axis=1),\n",
    "            validation_data=test_data_rf,\n",
    "            validation_data_scaled=test_data_sdd,\n",
    "            rf_model=best_rf_model,\n",
    "            lasso_model=best_lasso_model,\n",
    "            svm_model=best_svm_model\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c8e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
