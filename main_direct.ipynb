{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7525b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Local modules\n",
    "from module.data_loader import OsirisData\n",
    "from module.dataset import *\n",
    "from module.modeling import randomforestregressormodel_train, lassoregressionmodel_train, supportvectormachinemodel_train\n",
    "from module.modeling import randomforestregressormodel_pred, lassoregressionmodel_pred, supportvectormachinemodel_pred\n",
    "from module.features import *\n",
    "from module.settings import load_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b39c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"AANW_PCT6\",\"TOTAALAANW6\",\"AANW_PCT10\",\"TOTAALAANW10\"]\n",
    "week0 = [\"AANW_PCT3\",\"TOTAALAANW3\",\"AANW_PCT6\",\"TOTAALAANW6\",\"AANW_PCT10\",\"TOTAALAANW10\"]\n",
    "week3 = [\"AANW_PCT6\",\"TOTAALAANW6\",\"AANW_PCT10\",\"TOTAALAANW10\"]\n",
    "week6 = [\"AANW_PCT3\",\"TOTAALAANW3\",\"AANW_PCT10\",\"TOTAALAANW10\"]\n",
    "week10 = [\"AANW_PCT3\",\"TOTAALAANW3\",\"AANW_PCT6\",\"TOTAALAANW6\"]\n",
    "\n",
    "moment_selectie = week0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "630b8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which settings to load\n",
    "settings_type = 'custom'  # [default,custom] Change to 'custom' to load custom settings\n",
    "dataloader = \"db\" # Change to 'file' for file input \n",
    "\n",
    "team=\"BA\"\n",
    "pred_cohort = 2025\n",
    "train_cohort_min = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ddb914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrain_models': True, 'separator': ',', 'dropout_column': 'dropout', 'studentnumber_column': 'STUDENTNUMMER', 'save_method': 'xlsx', 'PROJ_ROOT': '.', 'DATA_DIR': './data', 'RAW_DATA_DIR': './data/raw', 'INTERIM_DATA_DIR': './data/interim', 'PROCESSED_DATA_DIR': './data/processed', 'EXTERNAL_DATA_DIR': './data/external', 'MODELS_DIR': './models', 'synth_data_dir_train': './data/raw/synth_data_train.csv', 'synth_data_dir_pred': './data/raw/synth_data_pred.csv', 'user_data_dir_train': './data/raw/user_data/train.csv', 'user_data_dir_pred': './data/raw/user_data/pred.csv', 'random_seed': 42, 'rf_parameters': {'bootstrap': [True, False], 'max_depth': [2, 3, 4], 'max_features': [3, 4, 5], 'min_samples_leaf': [3, 4, 5], 'min_samples_split': [2, 3, 5], 'n_estimators': [100, 200, 300]}, 'lasso_parameters': {'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9]}, 'svm_parameters': {'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1], 'kernel': ['rbf']}}\n"
     ]
    }
   ],
   "source": [
    "config_file = 'config.yaml'\n",
    "settings = load_settings(config_file, settings_type)\n",
    "print(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23cac45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__ Init done __\n",
      "inschrijvingen geladen...\n",
      "verzuimdata geladen...\n",
      "vooropleidingdata geladen...\n"
     ]
    }
   ],
   "source": [
    "# Check if train.csv and pred.csv exist in user_data folder, otherwise load synthetic datasests\n",
    "# When user data is loaded and an error occurs here, please check if the sep = '\\t' needs to be changed in the config.yaml file to another separator like ',' or '.'\n",
    "# This should be the same as the separator used in your .csv file\n",
    "\n",
    "if dataloader == 'file':\n",
    "    if os.path.exists(settings.user_data_dir_train) and os.path.exists(settings.user_data_dir_pred):\n",
    "        train_path,pred_path = user_data_dir_train, user_data_dir_pred\n",
    "        print ('User datasets found')\n",
    "    else:\n",
    "        train_path,pred_path = settings.synth_data_dir_train, settings.synth_data_dir_pred\n",
    "        print ('Pre-uploaded synthetic datasets found')\n",
    "        \n",
    "    # train_df = pd.read_csv(train_path, sep = separator, engine='python')\n",
    "    pred_df = pd.read_csv(pred_path, sep = separator, engine='python')\n",
    "elif dataloader == 'db':\n",
    "    db = OsirisData(env_path=\"./\")\n",
    "    # train_df = db.get_dataset(team=\"BB\",min_cohort=train_cohort_min,max_cohort=pred_cohort-1)\n",
    "    pred_df = db.get_dataset(team=team,min_cohort=pred_cohort,max_cohort=pred_cohort)\n",
    "drp_cols = [x for x in moment_selectie if x in pred_df.columns]\n",
    "pred_df = pred_df.drop(columns=drp_cols, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efdfedde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STUDENTNUMMER', 'STUD_GENDER_M', 'STUD_GENDER_V', 'STUD_GENDER_O',\n",
       "       'LEEFTIJD', 'SOPL_LW_BOL', 'SOPL_LW_BBL', 'SOPL_NIV1', 'SOPL_NIV2',\n",
       "       'SOPL_NIV3', 'SOPL_NIV4', 'VOOROPLNIVEAU_NAN', 'VOOROPLNIVEAU_HAVO',\n",
       "       'VOOROPLNIVEAU_VMBO_BB', 'VOOROPLNIVEAU_VMBO_GL',\n",
       "       'VOOROPLNIVEAU_VMBO_KB', 'VOOROPLNIVEAU_VMBO_TL', 'VOOROPLNIVEAU_VWO',\n",
       "       'VOOROPLNIVEAU_MBO', 'VOOROPLNIVEAU_HO', 'TEAM', 'dropout'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b43c1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inschrijvingen geladen...\n",
      "verzuimdata geladen...\n",
      "vooropleidingdata geladen...\n"
     ]
    }
   ],
   "source": [
    "if settings.retrain_models == True:\n",
    "    if dataloader == 'file':\n",
    "        train_df = pd.read_csv(train_path, sep = separator, engine='python')\n",
    "    elif dataloader == 'db':\n",
    "        # pred_cohort = 2024\n",
    "        # train_cohort_min = 2023\n",
    "        # db = OsirisData(env_path=\"./\")\n",
    "        train_df = db.get_dataset(team=team,min_cohort=train_cohort_min,max_cohort=pred_cohort-1)\n",
    "    drp_cols = [x for x in moment_selectie if x in train_df.columns]\n",
    "    train_df = train_df.drop(columns=drp_cols, errors='ignore')\n",
    "        # pred_df = db.get_dataset(team=\"BB\",min_cohort=pred_cohort,max_cohort=pred_cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ffb433f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data cleaning: drop rows that are duplicate and change any NA values to the average value of the column it's in. \n",
    "if settings.retrain_models == True:\n",
    "    train_basic_cl = basic_cleaning (train_df)\n",
    "pred_basic_cl = basic_cleaning (pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30a0a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if there are columns in which all rows have the same value and delete these columns from the train and predict datasets \n",
    "if settings.retrain_models == True:\n",
    "    train_cleaned, pred_cleaned = remove_single_value_columns(train_basic_cl, pred_basic_cl)\n",
    "else: \n",
    "    train_cleaned, pred_cleaned = remove_single_value_columns(pred_basic_cl, pred_basic_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61f5206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned[settings.studentnumber_column]=train_cleaned[settings.studentnumber_column].astype(\"int\")\n",
    "pred_cleaned[settings.studentnumber_column]=pred_cleaned[settings.studentnumber_column].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c8e9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function that changes categorical data into numerical data so it can be used as input for the models \n",
    "train_processed, pred_processed = convert_categorical_to_dummies(train_cleaned, pred_cleaned, settings.dropout_column, settings.separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d9d74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the function standardize_min_max to standardize the train and pred datasets using a min max scaler and save them as .csv files in the folder data/interim \n",
    "# These datasets can be used for the lasso and svm models, because reggression is sensitive to scaling \n",
    "train_df_sdd, pred_df_sdd = standardize_dataset(train_processed, pred_processed, settings.dropout_column, settings.separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea90352c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models on the data...\n",
      "Training random_forest_regressor\n",
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n",
      "Training lasso_regression\n",
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n",
      "Training support_vector_machine\n",
      "{'probability': True}\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    }
   ],
   "source": [
    "# Code checks if retrain_models = True or False in config.yaml file. \n",
    "# When using your own datasets, change retrain_models in the config.yaml file to True, so the models are trained on your own data. \n",
    "# Warning: training the models can take a long time depending on the size and contents of your data. \n",
    "if settings.retrain_models == True:\n",
    "    print ('Training models on the data...')\n",
    "    best_rf_model = randomforestregressormodel_train(\n",
    "        train_processed, settings.random_seed\n",
    "        , settings.dropout_column, settings.rf_parameters)\n",
    "    best_lasso_model = lassoregressionmodel_train(\n",
    "        train_df_sdd, settings.random_seed\n",
    "        , settings.dropout_column, settings.lasso_parameters)\n",
    "    best_svm_model = supportvectormachinemodel_train(\n",
    "        train_df_sdd, settings.random_seed\n",
    "        , settings.dropout_column, settings.svm_parameters)\n",
    "else:\n",
    "    print('retrain_models is False in the config.yaml file, loading the pre-trained models')\n",
    "# Folds = number of train/test splits of the dataset, candidates = models with different parameters and fits = folds * candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abad1f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STUD_GENDER_M', 'STUD_GENDER_V', 'LEEFTIJD', 'SOPL_LW_BOL',\n",
       "       'SOPL_LW_BBL', 'SOPL_NIV3', 'SOPL_NIV4', 'VOOROPLNIVEAU_NAN',\n",
       "       'VOOROPLNIVEAU_HAVO', 'VOOROPLNIVEAU_VMBO_BB', 'VOOROPLNIVEAU_VMBO_GL',\n",
       "       'VOOROPLNIVEAU_VMBO_KB', 'VOOROPLNIVEAU_VMBO_TL', 'VOOROPLNIVEAU_MBO',\n",
       "       'dropout'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c79637b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STUDENTNUMMER', 'STUD_GENDER_M', 'STUD_GENDER_V', 'LEEFTIJD',\n",
       "       'SOPL_LW_BOL', 'SOPL_LW_BBL', 'SOPL_NIV3', 'SOPL_NIV4',\n",
       "       'VOOROPLNIVEAU_NAN', 'VOOROPLNIVEAU_HAVO', 'VOOROPLNIVEAU_VMBO_BB',\n",
       "       'VOOROPLNIVEAU_VMBO_GL', 'VOOROPLNIVEAU_VMBO_KB',\n",
       "       'VOOROPLNIVEAU_VMBO_TL', 'VOOROPLNIVEAU_MBO', 'dropout'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_processed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7087355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the loaded models to predict on the datasets. \n",
    "# The lasso and SVM models use the standardized dataset ot predict an, but take the student numnbers from the \n",
    "# regular predict dataset. \n",
    "ranked_students_rf = randomforestregressormodel_pred (pred_processed, settings.dropout_column, settings.studentnumber_column)\n",
    "ranked_students_lasso = lassoregressionmodel_pred(pred_df_sdd, pred_processed, settings.dropout_column, settings.studentnumber_column)\n",
    "ranked_students_svm = supportvectormachinemodel_pred(pred_df_sdd, pred_processed, settings.dropout_column, settings.studentnumber_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54fe646d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('//dev-report-01/EXPORT/FRITS/Python/DGO-WG3/data')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the output files as either .xlsx or as three .csv files\n",
    "from pathlib import Path\n",
    "# __file__\n",
    "\n",
    "BASE_PATH = Path(os.getcwd()).parent\n",
    "DATA_PATH = BASE_PATH / 'data'\n",
    "OUT_PATH = DATA_PATH / 'output'\n",
    "# BASE_PATH = Path(\"Z:\\\\FRITS\\\\DGO-WG3\")\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d85b33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file saved as .xlsx in the \\\\dev-report-01\\EXPORT\\FRITS\\Python\\DGO-WG3\\data\\output folder\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if settings.save_method == 'xlsx':\n",
    "    writer = pd.ExcelWriter(OUT_PATH / f'{team}_ranked_students.xlsx', engine='xlsxwriter')\n",
    "    ranked_students_rf.to_excel(writer, sheet_name='Random Forest', startrow=0, startcol=0, index=False)\n",
    "    ranked_students_lasso.to_excel(writer, sheet_name='Lasso', startrow=0, startcol=0, index=False)\n",
    "    ranked_students_svm.to_excel(writer, sheet_name='Support Vector Machine', startrow=0, startcol=0, index=False)\n",
    "    writer.close()\n",
    "    print (f'Output file saved as .xlsx in the {OUT_PATH} folder')\n",
    "elif settings.save_method == 'csv':\n",
    "    ranked_students_rf.to_csv(OUT_PATH / f'{team}_ranked_students_rf.csv', sep='\\t', index=False)\n",
    "    ranked_students_lasso.to_csv(OUT_PATH / f'{team}_ranked_students_lasso.csv', sep='\\t', index=False)\n",
    "    ranked_students_svm.to_csv(OUT_PATH / f'{team}_ranked_students_svm.csv', sep='\\t', index=False)\n",
    "    print (f'Output files saved as .csv in the {OUT_PATH} folder')\n",
    "else:\n",
    "    print('Invalid save method. For save_method in the config.yaml file, please fill in \"xlsx\" or \"csv\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f8dbb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0758e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.plot import (\n",
    "    generate_precision_plot, \n",
    "    generate_sensitivity_plot, \n",
    "    generate_svm_importance_plot,\n",
    "    generate_stoplight_evaluation,\n",
    "    save_model_metrics,\n",
    "    save_threshold_analysis,\n",
    "    extract_model_data,\n",
    "    sort_and_filter_data,\n",
    "    process_evaluation_results,\n",
    "    display_model_results,\n",
    "    get_coefficient_table,\n",
    "    get_top_svm_features,\n",
    "    analyze_missing_data,\n",
    "    parse_model_metrics,\n",
    "    display_top_features\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot styling\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['axes.formatter.useoffset'] = False\n",
    "plt.rcParams['axes.formatter.limits'] = (-2, 2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355c104",
   "metadata": {},
   "source": [
    "### Validatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe706258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: stoplight-eval\n",
    "#| output: asis\n",
    "#| echo: false\n",
    "#| warning: false\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import tree\n",
    "# from contextlib import redirect_stdout, redirect_stderr\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "try:\n",
    "    # --- 1. Train/test split ---\n",
    "    # Use processed data for RF, scaled for Lasso/SVM\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        train_processed.drop(settings.dropout_column, axis=1),\n",
    "        train_processed[settings.dropout_column],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    X_train_sdd, X_test_sdd, y_train_sdd, y_test_sdd = train_test_split(\n",
    "        train_df_sdd.drop(settings.dropout_column, axis=1),\n",
    "        train_df_sdd[settings.dropout_column],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    # Prepare test sets for evaluation\n",
    "    test_data_rf = pd.concat([X_test, y_test], axis=1)\n",
    "    test_data_sdd = pd.concat([X_test_sdd, y_test_sdd], axis=1)\n",
    "\n",
    "    # Make test data available globally for plotting functions\n",
    "    globals()['test_data_rf'] = test_data_rf\n",
    "    globals()['test_data_sdd'] = test_data_sdd\n",
    "\n",
    "    # --- 2. Train or load models ---\n",
    "    # if settings.retrain_models:\n",
    "    #     # Suppress GridSearchCV output during training\n",
    "    #     with open(os.devnull, 'w') as fnull:\n",
    "    #         with redirect_stdout(fnull), redirect_stderr(fnull):\n",
    "    #             best_rf_model = randomforestregressormodel_train(pd.concat([X_train, y_train], axis=1), random_seed, dropout_column, rf_parameters)\n",
    "    #             best_lasso_model = lassoregressionmodel_train(pd.concat([X_train_sdd, y_train_sdd], axis=1), random_seed, dropout_column, alpha_range)\n",
    "    #             best_svm_model = supportvectormachinemodel_train(pd.concat([X_train_sdd, y_train_sdd], axis=1), random_seed, dropout_column, svm_parameters)\n",
    "    # else:\n",
    "    #     best_rf_model = joblib.load('models/random_forest_regressor.joblib')\n",
    "    #     best_lasso_model = joblib.load('models/lasso_regression.joblib')\n",
    "    #     best_svm_model = joblib.load('models/support_vector_machine.joblib')\n",
    "\n",
    "    # --- 3. Modular stoplight evaluation on test set ---\n",
    "    model_predictions = {\n",
    "        'Random Forest': (test_data_rf, best_rf_model, False),\n",
    "        'Lasso': (test_data_sdd, best_lasso_model, True),\n",
    "        'SVM': (test_data_sdd, best_svm_model, True)\n",
    "    }\n",
    "    \n",
    "    evaluation_results = generate_stoplight_evaluation(\n",
    "        model_predictions,\n",
    "        invite_pct=20\n",
    "    )\n",
    "\n",
    "    # --- 4. Save metrics and threshold analysis on test set ---\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        save_model_metrics(\n",
    "            train_data=pd.concat([X_train, y_train], axis=1),\n",
    "            train_data_scaled=pd.concat([X_train_sdd, y_train_sdd], axis=1),\n",
    "            validation_data=test_data_rf,\n",
    "            validation_data_scaled=test_data_sdd,\n",
    "            rf_model=best_rf_model,\n",
    "            lasso_model=best_lasso_model,\n",
    "            svm_model=best_svm_model\n",
    "        )\n",
    "        save_threshold_analysis(\n",
    "            train_data=pd.concat([X_train, y_train], axis=1),\n",
    "            train_data_scaled=pd.concat([X_train_sdd, y_train_sdd], axis=1),\n",
    "            validation_data=test_data_rf,\n",
    "            validation_data_scaled=test_data_sdd,\n",
    "            rf_model=best_rf_model,\n",
    "            lasso_model=best_lasso_model,\n",
    "            svm_model=best_svm_model\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"Error in stoplight evaluation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Process evaluation results using imported functions\n",
    "model_results, best_model, best_metrics, recommendation_display, recommendation_text = process_evaluation_results(evaluation_results)\n",
    "\n",
    "# print(recommendation_display)\n",
    "txt = \"\\n\\n\" + recommendation_text + \" Het best presterende model is: \\n\\n\" + best_model + \"\\n\\nHet laat de beste balans zien tussen precisie en recall bij een selectie van 20% van de studenten voor uitnodiging. \" +  \"Dit impliceert dat dit model het meest effectief is in het identificeren van studenten met een verhoogd risico op uitval.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d5ae840",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_precision = f\" - Precisie: {best_metrics['precision']:.1f}%\\n\"\n",
    "txt_recall = f\"- Recall: {best_metrics['recall']:.1f}%\\n\"\n",
    "txt_status = f\"- Status: {best_metrics['status']}\\n\"\n",
    "txt_summary = f\"\\n**Samenvatting:**\\n\"\n",
    "tbl_summary = best_metrics['dutch_summary']\n",
    "txt2 = \"\\n\".join([txt_precision, txt_recall, txt_status, txt_summary, tbl_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3048334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install git+https://github.com/innovationOUtside/fstring-magic.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c29d2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext fstring_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39021def",
   "metadata": {},
   "source": [
    "# Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18576d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "__🔴 🔴 🔴 Niet bruikbaar 🔴 🔴 🔴__\n",
       "\n",
       "\n",
       "\n",
       "Op basis van de evaluatie kan het model NIET worden gebruikt. Het best presterende model is: \n",
       "\n",
       "SVM\n",
       "\n",
       "Het laat de beste balans zien tussen precisie en recall bij een selectie van 20% van de studenten voor uitnodiging. Dit impliceert dat dit model het meest effectief is in het identificeren van studenten met een verhoogd risico op uitval.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fstring\n",
    "__{recommendation_display}__\n",
    "\n",
    "{txt}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e0426",
   "metadata": {},
   "source": [
    "<div class='disclaimer' style='padding: 15px; margin: 20px 0; border-left: 4px solid #ffc107;'>\n",
    "<strong>Belangrijke opmerking:</strong>\n",
    "<p>Deze evaluatie is automatisch gegenereerd en dient als richtlijn. De uiteindelijke beslissing over het gebruik van het model ligt bij de gebruiker. Het is belangrijk om:</p>\n",
    "<ul>\n",
    "      <li>De resultaten kritisch te evalueren in de context van uw specifieke situatie</li>\n",
    "      <li>De beperkingen van het model te begrijpen</li>\n",
    "      <li>De ethische implicaties van het gebruik te overwegen</li>\n",
    "      <li>De resultaten te valideren met domeinexperts</li>\n",
    "</ul>\n",
    "\n",
    "<p>De gebruiker is zelf verantwoordelijk voor de interpretatie en het gebruik van de modelresultaten.</p>\n",
    "</div>\n",
    "\n",
    "<p>Voor meer informatie over de gebruikte modellen wordt verwezen naar Hoofdstuk 2.</p>\n",
    "<p>Verdere details over de precisie, recall en model-specifieke analyses zijn te vinden in de latere hoofdstukken van dit rapport.</p>\n",
    "<p/>\n",
    "<h2>Prestaties van het aanbevolen model:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d8eabb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " - Precisie: 72.4%\n",
       "\n",
       "- Recall: 26.9%\n",
       "\n",
       "- Status: Niet bruikbaar\n",
       "\n",
       "\n",
       "**Samenvatting:**\n",
       "\n",
       "Bij 20% uitgenodigde studenten (29 uit 148 studenten):\n",
       "- 26.9% van alle uitvallers wordt geïdentificeerd (21 van 78 uitvallers)\n",
       "- 72.4% van de uitgenodigde studenten valt daadwerkelijk uit (21 van 29 uitgenodigde studenten)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fstring\n",
    "{txt2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8ed55",
   "metadata": {},
   "source": [
    "## **Toelichting:**\n",
    "- **Precisie (%):** Percentage van de uitgenodigde studenten dat daadwerkelijk uitvalt\n",
    "- **Recall (%):** Percentage van alle uitvallers dat wordt geïdentificeerd\n",
    "- **% Uitgenodigd:** Percentage van alle studenten dat wordt uitgenodigd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d472b",
   "metadata": {},
   "source": [
    "## Wat te controleren bij een slechte aanbeveling\n",
    "\n",
    "Wanneer een model een slechte aanbeveling doet, zijn er verschillende onderdelen in dit rapport die u kunt raadplegen om mogelijke oorzaken te achterhalen. Begin bij 3.3 Model Metrics om te controleren op tekenen van overfitting of underfitting, zoals grote verschillen tussen training en testresultaten of een negatieve R².\n",
    "\n",
    "Bekijk vervolgens hoofdstuk 4 (Data Kwaliteit) om te zien of er sprake is van ontbrekende of onbetrouwbare data die het model kan hebben beïnvloed.\n",
    "\n",
    "Tot slot bieden hoofdstukken 5, 6 en 7 inzicht in de prestaties en relevantie van individuele features. Een lage bijdrage of onverwacht gedrag van belangrijke variabelen kan verklaren waarom het model geen goede voorspelling doet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829eccbf",
   "metadata": {},
   "source": [
    "# Gedetailleerde Modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937fa141",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e3b41a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "🔴 🔴 🔴 Niet bruikbaar 🔴 🔴 🔴\n",
       "\n",
       "**Precisie:** 62.1%\n",
       "**Recall:** 23.1%\n",
       "**Status:** Niet bruikbaar\n",
       "**Evaluatie:** Model heeft verbetering nodig\n",
       "\n",
       "**Samenvatting:**\n",
       "Bij 20% uitgenodigde studenten (29 uit 148 studenten):\n",
       "- 23.1% van alle uitvallers wordt geïdentificeerd (18 van 78 uitvallers)\n",
       "- 62.1% van de uitgenodigde studenten valt daadwerkelijk uit (18 van 29 uitgenodigde studenten)\n",
       "\n",
       "**Prestaties bij Verschillende Uitnodigingspercentages**\n",
       "\n",
       "| % Uitgenodigd | Precisie (%) | Recall (%) |\n",
       "|:-------------:|:------------:|:----------:|\n",
       "|         5.0 |        71.4 |        6.4 |\n",
       "|        10.0 |        71.4 |       12.8 |\n",
       "|        15.0 |        63.6 |       17.9 |\n",
       "|        20.0 |        62.1 |       23.1 |\n",
       "|        25.0 |        67.6 |       32.1 |\n",
       "|        30.0 |        68.2 |       38.5 |\n",
       "|        40.0 |        64.4 |       48.7 |\n",
       "|        50.0 |        60.8 |       57.7 |\n",
       "|        60.0 |        59.1 |       66.7 |\n",
       "|        70.0 |        57.3 |       75.6 |\n",
       "|        80.0 |        55.9 |       84.6 |\n",
       "|        90.0 |        54.9 |       93.6 |\n",
       "|       100.0 |        52.7 |      100.0 |\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fstring\n",
    "{display_model_results(model_results, 'Random Forest')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11bedec",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7732f732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "🔴 🔴 🔴 Niet bruikbaar 🔴 🔴 🔴\n",
       "\n",
       "**Precisie:** 55.2%\n",
       "**Recall:** 20.5%\n",
       "**Status:** Niet bruikbaar\n",
       "**Evaluatie:** Model heeft verbetering nodig\n",
       "\n",
       "**Samenvatting:**\n",
       "Bij 20% uitgenodigde studenten (29 uit 148 studenten):\n",
       "- 20.5% van alle uitvallers wordt geïdentificeerd (16 van 78 uitvallers)\n",
       "- 55.2% van de uitgenodigde studenten valt daadwerkelijk uit (16 van 29 uitgenodigde studenten)\n",
       "\n",
       "**Prestaties bij Verschillende Uitnodigingspercentages**\n",
       "\n",
       "| % Uitgenodigd | Precisie (%) | Recall (%) |\n",
       "|:-------------:|:------------:|:----------:|\n",
       "|         5.0 |        42.9 |        3.8 |\n",
       "|        10.0 |        57.1 |       10.3 |\n",
       "|        15.0 |        63.6 |       17.9 |\n",
       "|        20.0 |        55.2 |       20.5 |\n",
       "|        25.0 |        59.5 |       28.2 |\n",
       "|        30.0 |        63.6 |       35.9 |\n",
       "|        40.0 |        61.0 |       46.2 |\n",
       "|        50.0 |        64.9 |       61.5 |\n",
       "|        60.0 |        58.0 |       65.4 |\n",
       "|        70.0 |        56.3 |       74.4 |\n",
       "|        80.0 |        55.9 |       84.6 |\n",
       "|        90.0 |        54.1 |       92.3 |\n",
       "|       100.0 |        52.7 |      100.0 |\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fstring \n",
    "{display_model_results(model_results, 'Lasso')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba9da7",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e0a3366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "🔴 🔴 🔴 Niet bruikbaar 🔴 🔴 🔴\n",
       "\n",
       "**Precisie:** 72.4%\n",
       "**Recall:** 26.9%\n",
       "**Status:** Niet bruikbaar\n",
       "**Evaluatie:** Model heeft verbetering nodig\n",
       "\n",
       "**Samenvatting:**\n",
       "Bij 20% uitgenodigde studenten (29 uit 148 studenten):\n",
       "- 26.9% van alle uitvallers wordt geïdentificeerd (21 van 78 uitvallers)\n",
       "- 72.4% van de uitgenodigde studenten valt daadwerkelijk uit (21 van 29 uitgenodigde studenten)\n",
       "\n",
       "**Prestaties bij Verschillende Uitnodigingspercentages**\n",
       "\n",
       "| % Uitgenodigd | Precisie (%) | Recall (%) |\n",
       "|:-------------:|:------------:|:----------:|\n",
       "|         5.0 |        71.4 |        6.4 |\n",
       "|        10.0 |        78.6 |       14.1 |\n",
       "|        15.0 |        68.2 |       19.2 |\n",
       "|        20.0 |        72.4 |       26.9 |\n",
       "|        25.0 |        75.7 |       35.9 |\n",
       "|        30.0 |        77.3 |       43.6 |\n",
       "|        40.0 |        67.8 |       51.3 |\n",
       "|        50.0 |        64.9 |       61.5 |\n",
       "|        60.0 |        60.2 |       67.9 |\n",
       "|        70.0 |        59.2 |       78.2 |\n",
       "|        80.0 |        55.1 |       83.3 |\n",
       "|        90.0 |        53.4 |       91.0 |\n",
       "|       100.0 |        52.7 |      100.0 |\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%fstring \n",
    "{display_model_results(model_results, 'SVM')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecafb085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2887e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
